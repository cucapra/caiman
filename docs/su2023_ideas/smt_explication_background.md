# Caiman Background

Caiman is a language designed for ease of exploration in heterogeneous compute
settings.  The key idea for Caiman is the existence of a program behavior
specification in the form of a value language (what computations happen)
compared to a scheduling language (when and where these things happen).  In
particular, Caiman is focused on having highly decomposable schedules, meaning
that an operation can be broken down to reflect the dependencies of that
operation.

## The Problem

However, this amount of control comes at a usability cost -- if you specify
every detail of a program at a granular level, you will go completely mad.
Consider a simple recursive program written in Caiman.  The value code is a bit
unusual looking, but simple enough to write (syntax pending):

```
// sum the numbers from 1 to x
value sum(x : i32) -> i32 {
    left := (sum (- x 1)). // recursion only executes if 'left' is used
    left_res := (+ x left).
    check := (= x 0).
    result := (if check left_res 0). // this can come last, totally fine
    returns result.
}
```

The schedule for even this program is annoyingly complicated if you write it out
fully explicitly (and this is with simplified if pending syntax, in caiman
assembly, this was far more code):

```
schedule sum_sch(x : slot) : sum -> slot {
    check = allocate-cpu $check; // first thing we need
    zero = allocate const 0;
    check <- $check.call(x, zero);

    // return the result of this expression, since possibly no allocation needed
    return {
        $result.if(check) {
            left_res = allocate-cpu $left_res;
            // could be passed in, but to illustrate
            one = allocate-cpu const 1; 

            // storing exactly once
            left_res <- $left.call.call(x, one);
            // stateful update
            left_res <- $left.call(left_res);
            // note that order matters!
            // this is all type-checked though
            left_res <- $left_res.call(x, left_res);
            left_res // return
        }
        else { 
            zero
        }
    }
}
```

## Explication

For even more complicated programs, this gets out of hand quickly. Perhaps more
immediately, however, a lot of this is sort of...obviously silly.  Having the
programmer do all the work of keeping track of allocation names seems reduntant
when the main goal should be to specify the order and location of things.

Indeed, since you have a value, it (will be) perfectly possible to just let the
compiler figuring everything out!  By the type-system guarantees of Caiman, the
compiler can't "get this wrong".  So it's perfectly reasonable to have a
schedule for `sum` as follows:

```
schedule sum_sch(_ : slot) : sum -> slot {
    ???
}
```

Once explication is setup, this will compile and run!  The `???` means "fill in
what you need to fill in", and the compiler can do that, it has sufficient
information to figure out what's needed.  

However, this sort of defeats the purpose of Caiman as a concept; if the
compiler was smart enough to figure out a good schedule, the notion of
"decomposable exploration" isn't terribly useful. As a result, what we want is a
sort of compromise, where the programmer can specify as much as they'd like, and
let the compiler fill in the rest.

In particular, my current work is focused on making something like this work as
a schedule for the `sum` value function:

```
schedule sum_sch(_ : slot) : sum -> slot {
    allocate-cpu $check; // first thing we need
    ??? // setup check

    // return the result of this expression, since possibly no allocation needed
    return {
        $result.if(?) {
            left_res = allocate-gpu $left_res;
            ??? // allows for any number of allocations, in this case `one`

            // find and fill in what you need
            // note that the extra node can be generated by the `???` above
            $left.call(?);
            $left_res.call(?);
            left_res
        }
        else { 
            ???
        }
    }
}
```

Here, we were able to specify that the check lives on the cpu and the result
lives on the GPU, which is likely enough for the compiler to reasonably infer
the rest.  Note that one goal would be to see what the explicator works out if
you want to see it, but that's an aside.

Fortunately for the sake of research, explication opens up a bunch of
interesting problems.